{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML bpalazzo_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7fDTPpHZZKv"
      },
      "source": [
        "## Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "aDNNkHdKW4fN",
        "outputId": "1e5d8bd5-d2c1-4ff6-b98a-5c72d8c437c1"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgXTOspVXQcl"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "# The Embedding layer takes at least two arguments:\n",
        "# the number of possible tokens, here 1000 (1 + maximum word index),\n",
        "# and the dimensionality of the embeddings, here 64.\n",
        "embedding_layer = Embedding(1000, 64)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3LyJQeU5XYGV",
        "outputId": "605106f8-e73e-4849-dd97-4f64260004d0"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "\n",
        "# Number of words to consider as features\n",
        "max_features = 10000\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "maxlen = 150\n",
        "\n",
        "# Load the data as lists of integers.\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# This turns our lists of integers\n",
        "# into a 2D integer tensor of shape `(samples, maxlen)`\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J5iRBLwzksGt",
        "outputId": "e9d3debb-082f-4b9a-e50f-349b44ff7512"
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DuqZTwYVXbvN",
        "outputId": "0d52edb1-a629-4723-d111-d1730f5ac190"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "# We specify the maximum input length to our Embedding layer\n",
        "# so we can later flatten the embedded inputs\n",
        "model.add(Embedding(10000, 8, input_length=maxlen))\n",
        "# After the Embedding layer, \n",
        "# our activations have shape `(samples, maxlen, 8)`.\n",
        "\n",
        "# We flatten the 3D tensor of embeddings \n",
        "# into a 2D tensor of shape `(samples, maxlen * 8)`\n",
        "model.add(Flatten())\n",
        "\n",
        "# We add the classifier on top\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 150, 8)            80000     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 1201      \n",
            "=================================================================\n",
            "Total params: 81,201\n",
            "Trainable params: 81,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6708 - acc: 0.5891 - val_loss: 0.4483 - val_acc: 0.8198\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.3713 - acc: 0.8647 - val_loss: 0.3214 - val_acc: 0.8672\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.2578 - acc: 0.8980 - val_loss: 0.3004 - val_acc: 0.8736\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.2105 - acc: 0.9189 - val_loss: 0.2930 - val_acc: 0.8748\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.1822 - acc: 0.9309 - val_loss: 0.2953 - val_acc: 0.8778\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.1550 - acc: 0.9438 - val_loss: 0.3054 - val_acc: 0.8728\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.1326 - acc: 0.9531 - val_loss: 0.3164 - val_acc: 0.8718\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.1147 - acc: 0.9619 - val_loss: 0.3220 - val_acc: 0.8694\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.1015 - acc: 0.9664 - val_loss: 0.3351 - val_acc: 0.8708\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0831 - acc: 0.9745 - val_loss: 0.3495 - val_acc: 0.8636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-dldC5eZqX5"
      },
      "source": [
        "## Pre-trained Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gbQXwE0mcM9v",
        "outputId": "47cdefa1-9f8a-41a0-950a-d07f56d40733"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3hEwXP6ffs5"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "imdb_dir = '/content/gdrive/MyDrive/ML Assignment 3/aclImdb'\n",
        "train_dir = '/content/gdrive/MyDrive/ML Assignment 3/aclImdb/train'\n",
        "#train_dir = os.path.join(imdb_dir, 'train')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(train_dir, label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            texts.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wi1H7c9BmzPj",
        "outputId": "84b31e8b-198b-4911-c08b-c638b5a3d4ff"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "maxlen = 150  # We will cut reviews after 150 words\n",
        "training_samples = 100  # We will be training on 100 samples\n",
        "validation_samples = 10000  # We will be validating on 10000 samples\n",
        "max_words = 10000  # We will only consider the top 10,000 words in the dataset\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Split the data into a training set and a validation set\n",
        "# But first, shuffle the data, since we started from data\n",
        "# where sample are ordered (all negative first, then all positive).\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 88582 unique tokens.\n",
            "Shape of data tensor: (25000, 150)\n",
            "Shape of label tensor: (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kybkDb7H4c7e",
        "outputId": "3da8c3b8-f920-45fa-f80a-430634bd31d6"
      },
      "source": [
        "glove_dir = '/content/gdrive/MyDrive/ML Assignment 3/glove6B'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400001 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1WDb1ZV43MC"
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rCcjB3dV5GRw",
        "outputId": "5f1d5b8c-3f66-4b71-fa7d-3e3f6580b680"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 150, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 15000)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                480032    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,480,065\n",
            "Trainable params: 1,480,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPe16TZt5LUt"
      },
      "source": [
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IgYBTQw55OgB",
        "outputId": "8910ae3b-235d-452e-d840-bc1add35c212"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val))\n",
        "model.save_weights('pre_trained_glove_model.h5')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 2.5702 - acc: 0.5019 - val_loss: 1.8446 - val_acc: 0.4979\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.1649 - acc: 0.5280 - val_loss: 1.3421 - val_acc: 0.4979\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 0.6219 - acc: 0.6820 - val_loss: 1.1974 - val_acc: 0.4979\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 0.2262 - acc: 0.9187 - val_loss: 0.8204 - val_acc: 0.5166\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 0.1360 - acc: 0.9845 - val_loss: 0.7795 - val_acc: 0.5392\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 0.0875 - acc: 1.0000 - val_loss: 0.7468 - val_acc: 0.5507\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 0.0364 - acc: 1.0000 - val_loss: 1.0611 - val_acc: 0.5065\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 0.0288 - acc: 1.0000 - val_loss: 1.0194 - val_acc: 0.5192\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.9418 - val_acc: 0.5345\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.8271 - val_acc: 0.5541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "tv4jkn4Y5U-t",
        "outputId": "ca11647f-530b-422b-f3b4-9e48a8899dc6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8ddHiCyCIBA3EIK3CopCAgFU1ILaul5wbUGqUluptHVttagVcMHrbbl9eG2rFndtKnrVn3WtrQviigZEBEVFBI2gYpCtrNHP74/vCUxilkkyyZmcvJ+Pxzwy58yZM59M4D3f+Z7vOV9zd0REpPnbIe4CREQkMxToIiIJoUAXEUkIBbqISEIo0EVEEkKBLiKSEAp0qZKZPWVmZ2V62ziZ2VIzO6oR9utm9p3o/i1mdmU629bjdcaa2T/rW2cN+x1uZiWZ3q80vdZxFyCZY2brUxbbA5uBr6Pln7l7Ubr7cvdjG2PbpHP3czOxHzPLAz4Ccty9LNp3EZD231BaHgV6grh7h/L7ZrYU+Km7P1N5OzNrXR4SIpIc6nJpAcq/UpvZb8zsM+BOM9vFzB43s5Vm9lV0v0fKc2aa2U+j++PM7CUzmxZt+5GZHVvPbXub2SwzW2dmz5jZn83sr9XUnU6N15jZy9H+/mlm3VIeP8PMlplZqZldUcP7M9TMPjOzVinrTjKz+dH9IWb2qpmtNrMVZvYnM9uxmn3dZWbXpixfEj1nuZmdXWnb483sTTNba2afmNmUlIdnRT9Xm9l6Mzu4/L1Nef4hZvaGma2Jfh6S7ntTEzPbL3r+ajNbaGYjUx47zszeifb5qZn9OlrfLfr7rDazVWb2opkpX5qY3vCWY3egC9ALGE/4298ZLfcENgJ/quH5Q4H3gG7A74Dbzczqse3fgNeBrsAU4IwaXjOdGk8HfgzsCuwIlAfM/sDN0f73jF6vB1Vw99nAv4EjKu33b9H9r4GLot/nYOBI4Oc11E1UwzFRPd8D9gEq99//GzgT6AwcD0wwsxOjxw6PfnZ29w7u/mqlfXcBngBujH63PwBPmFnXSr/Dt96bWmrOAR4D/hk97zygyMz6RJvcTui+6wgcADwXrf8VUALkArsBlwO6rkgTU6C3HN8Ak919s7tvdPdSd3/I3Te4+zpgKvDdGp6/zN1vdfevgbuBPQj/cdPe1sx6AoOBSe6+xd1fAh6t7gXTrPFOd3/f3TcCDwD50fpTgcfdfZa7bwaujN6D6twHjAEws47AcdE63H2Ou7/m7mXuvhT4SxV1VOUHUX0L3P3fhA+w1N9vpru/7e7fuPv86PXS2S+ED4AP3P3eqK77gEXAf6ZsU917U5ODgA7A9dHf6DngcaL3BtgK7G9mO7v7V+4+N2X9HkAvd9/q7i+6LhTV5BToLcdKd99UvmBm7c3sL1GXxFrCV/zOqd0OlXxWfsfdN0R3O9Rx2z2BVSnrAD6pruA0a/ws5f6GlJr2TN13FKil1b0WoTV+spm1AU4G5rr7sqiOfaPuhM+iOq4jtNZrU6EGYFml32+omT0fdSmtAc5Nc7/l+15Wad0yoHvKcnXvTa01u3vqh1/qfk8hfNgtM7MXzOzgaP3vgcXAP81siZlNTO/XkExSoLcclVtLvwL6AEPdfWe2f8WvrhslE1YAXcysfcq6vWrYviE1rkjdd/SaXavb2N3fIQTXsVTsboHQdbMI2Ceq4/L61EDoNkr1N8I3lL3cvRNwS8p+a2vdLid0RaXqCXyaRl217XevSv3f2/br7m+4+yhCd8wjhJY/7r7O3X/l7nsDI4GLzezIBtYidaRAb7k6EvqkV0f9sZMb+wWjFm8xMMXMdoxad/9Zw1MaUuODwAlmdmh0APNqav/3/jfgAsIHx/9VqmMtsN7M+gIT0qzhAWCcme0ffaBUrr8j4RvLJjMbQvggKbeS0EW0dzX7fhLY18xON7PWZvZDYH9C90hDzCa05i81sxwzG074G82I/mZjzayTu28lvCffAJjZCWb2nehYyRrCcYeaurikESjQW64bgHbAl8BrwD+a6HXHEg4slgLXAvcTxstXpd41uvtC4BeEkF4BfEU4aFeT8j7s59z9y5T1vyaE7Trg1qjmdGp4KvodniN0RzxXaZOfA1eb2TpgElFrN3ruBsIxg5ejkSMHVdp3KXAC4VtMKXApcEKluuvM3bcQAvxYwvt+E3Cmuy+KNjkDWBp1PZ1L+HtCOOj7DLAeeBW4yd2fb0gtUnem4xYSJzO7H1jk7o3+DUEk6dRClyZlZoPN7D/MbIdoWN8oQl+siDSQzhSVprY78DDhAGUJMMHd34y3JJFkUJeLiEhCqMtFRCQhYuty6datm+fl5cX18iIizdKcOXO+dPfcqh6LLdDz8vIoLi6O6+VFRJolM6t8hvA26nIREUkIBbqISELUGuhm1tbMXjezt6JrI19VxTbjogsMzYtuP22cckVEpDrp9KFvBo5w9/XRtZJfMrOn3P21Stvd7+6/zHyJIpIpW7dupaSkhE2bNtW+scSqbdu29OjRg5ycnLSfU2ugR9c0Lp+rMie6afC6SDNUUlJCx44dycvLo/r5SSRu7k5paSklJSX07t077eel1YduZq3MbB7wBfCvaIaXyk4xs/lm9qCZVXlJVDMbb2bFZla8cuXKtIssV1QEeXmwww7hZ5GmyxWpk02bNtG1a1eFeZYzM7p27Vrnb1JpBbq7f+3u+YQpvIaY2QGVNnkMyHP3/sC/CLPUVLWf6e5e6O6FublVDqOsVlERjB8Py5aBe/g5frxCXaSuFObNQ33+TnUa5eLuq4HngWMqrS+NpvkCuA0YVOdKanHFFbBhQ8V1GzaE9SIikt4ol1wz6xzdb0eY8HZRpW32SFkcCbybySIBPv64butFJPuUlpaSn59Pfn4+u+++O927d9+2vGXLlhqfW1xczPnnn1/raxxyyCEZqXXmzJmccMIJGdlXU0lnlMsewN3RPI47AA+4++NmdjVQ7O6PAueb2UigDFgFjMt0oT17hm6WqtaLSOMoKgrfgj/+OPxfmzoVxo6t/XnV6dq1K/PmzQNgypQpdOjQgV//+tfbHi8rK6N166pjqbCwkMLCwlpf45VXXql/gc1crS10d5/v7gXu3t/dD3D3q6P1k6Iwx90vc/d+7j7A3UekzG6SMVOnQvv2Fde1bx/Wi0jmNdVxq3HjxnHuuecydOhQLr30Ul5//XUOPvhgCgoKOOSQQ3jvvfeAii3mKVOmcPbZZzN8+HD23ntvbrzxxm3769Chw7bthw8fzqmnnkrfvn0ZO3Ys5VeXffLJJ+nbty+DBg3i/PPPr7UlvmrVKk488UT69+/PQQcdxPz58wF44YUXtn3DKCgoYN26daxYsYLDDz+c/Px8DjjgAF588cXMvmE1aDbXQy9vFWSytSAi1avpuFWm/9+VlJTwyiuv0KpVK9auXcuLL75I69ateeaZZ7j88st56KGHvvWcRYsW8fzzz7Nu3Tr69OnDhAkTvjVm+80332ThwoXsueeeDBs2jJdffpnCwkJ+9rOfMWvWLHr37s2YMWNqrW/y5MkUFBTwyCOP8Nxzz3HmmWcyb948pk2bxp///GeGDRvG+vXradu2LdOnT+foo4/miiuu4Ouvv2ZD5TexETWbQIfwj0gBLtI0mvK41WmnnUarVq0AWLNmDWeddRYffPABZsbWrVurfM7xxx9PmzZtaNOmDbvuuiuff/45PXr0qLDNkCFDtq3Lz89n6dKldOjQgb333nvb+O4xY8Ywffr0Gut76aWXtn2oHHHEEZSWlrJ27VqGDRvGxRdfzNixYzn55JPp0aMHgwcP5uyzz2br1q2ceOKJ5OfnN+i9qQtdy0VEqlTd8anGOG610047bbt/5ZVXMmLECBYsWMBjjz1W7VjsNm3abLvfqlUrysrK6rVNQ0ycOJHbbruNjRs3MmzYMBYtWsThhx/OrFmz6N69O+PGjeOee+7J6GvWRIEuIlWK67jVmjVr6N69OwB33XVXxvffp08flixZwtKlSwG4//77a33OYYcdRlF08GDmzJl069aNnXfemQ8//JADDzyQ3/zmNwwePJhFixaxbNkydtttN8455xx++tOfMnfu3Iz/DtVRoItIlcaOhenToVcvMAs/p09v/G7PSy+9lMsuu4yCgoKMt6gB2rVrx0033cQxxxzDoEGD6NixI506darxOVOmTGHOnDn079+fiRMncvfd4dzJG264gQMOOID+/fuTk5PDsccey8yZMxkwYAAFBQXcf//9XHDBBRn/HaoT25yihYWFrgkuRJrWu+++y3777Rd3GbFbv349HTp0wN35xS9+wT777MNFF10Ud1nfUtXfy8zmuHuV4zfVQheRFufWW28lPz+ffv36sWbNGn72s5/FXVJGNKtRLiIimXDRRRdlZYu8odRCFxFJCAW6iEhCKNBFRBJCgS4ikhAKdBFpMiNGjODpp5+usO6GG25gwoQJ1T5n+PDhlA9xPu6441i9evW3tpkyZQrTpk2r8bUfeeQR3nnnnW3LkyZN4plnnqlL+VXKpsvsKtBFpMmMGTOGGTNmVFg3Y8aMtC6QBeEqiZ07d67Xa1cO9KuvvpqjjjqqXvvKVgp0EWkyp556Kk888cS2ySyWLl3K8uXLOeyww5gwYQKFhYX069ePyZMnV/n8vLw8vvzySwCmTp3Kvvvuy6GHHrrtErsQxpgPHjyYAQMGcMopp7BhwwZeeeUVHn30US655BLy8/P58MMPGTduHA8++CAAzz77LAUFBRx44IGcffbZbN68edvrTZ48mYEDB3LggQeyaFHNVwaP+zK7Gocu0kJdeCFEc01kTH4+3HBD9Y936dKFIUOG8NRTTzFq1ChmzJjBD37wA8yMqVOn0qVLF77++muOPPJI5s+fT//+/avcz5w5c5gxYwbz5s2jrKyMgQMHMmhQmPny5JNP5pxzzgHgt7/9LbfffjvnnXceI0eO5IQTTuDUU0+tsK9NmzYxbtw4nn32Wfbdd1/OPPNMbr75Zi688EIAunXrxty5c7npppuYNm0at912W7W/X9yX2VULXUSaVGq3S2p3ywMPPMDAgQMpKChg4cKFFbpHKnvxxRc56aSTaN++PTvvvDMjR47c9tiCBQs47LDDOPDAAykqKmLhwoU11vPee+/Ru3dv9t13XwDOOussZs2ate3xk08+GYBBgwZtu6BXdV566SXOOOMMoOrL7N54442sXr2a1q1bM3jwYO68806mTJnC22+/TceOHWvcdzrUQhdpoWpqSTemUaNGcdFFFzF37lw2bNjAoEGD+Oijj5g2bRpvvPEGu+yyC+PGjav2srm1GTduHI888ggDBgzgrrvuYubMmQ2qt/wSvA25/O7EiRM5/vjjefLJJxk2bBhPP/30tsvsPvHEE4wbN46LL76YM888s0G1qoUuIk2qQ4cOjBgxgrPPPntb63zt2rXstNNOdOrUic8//5ynnnqqxn0cfvjhPPLII2zcuJF169bx2GOPbXts3bp17LHHHmzdunXbJW8BOnbsyLp16761rz59+rB06VIWL14MwL333st3v/vdev1ucV9mt9YWupm1BWYBbaLtH3T3yZW2aQPcAwwCSoEfuvvSBlcnIok0ZswYTjrppG1dL+WXm+3bty977bUXw4YNq/H5AwcO5Ic//CEDBgxg1113ZfDgwdseu+aaaxg6dCi5ubkMHTp0W4iPHj2ac845hxtvvHHbwVCAtm3bcuedd3LaaadRVlbG4MGDOffcc+v1e5XPddq/f3/at29f4TK7zz//PDvssAP9+vXj2GOPZcaMGfz+978nJyeHDh06ZGQijFovn2tmBuzk7uvNLAd4CbjA3V9L2ebnQH93P9fMRgMnufsPa9qvLp8r0vR0+dzmJeOXz/VgfbSYE90qfwqMAu6O7j8IHBl9EIiISBNJqw/dzFqZ2TzgC+Bf7j670ibdgU8A3L0MWAN0zWShIiJSs7QC3d2/dvd8oAcwxMwOqM+Lmdl4Mys2s+KVK1fWZxci0kBxzVImdVOfv1OdRrm4+2rgeeCYSg99CuwFYGatgU6Eg6OVnz/d3QvdvTA3N7fOxYpIw7Rt25bS0lKFepZzd0pLS2nbtm2dnpfOKJdcYKu7rzazdsD3gP+utNmjwFnAq8CpwHOufzEiWadHjx6UlJSgb8jZr23btvTo0aNOz0nnxKI9gLvNrBWhRf+Auz9uZlcDxe7+KHA7cK+ZLQZWAaPrVrqINIWcnBx69+4ddxnSSGoNdHefDxRUsX5Syv1NwGmZLU1EROpCZ4qKiCSEAl1EJCEU6CIiCaFAFxFJCAW6iEhCKNBFRBJCgS4ikhAKdBGRhFCgi4gkhAJdRCQhFOgiIgmhQBcRSQgFuohIQijQRUQSQoEuIpIQCnQRkYRQoIuIJIQCXUQkIRToIiIJoUAXEUmIWgPdzPYys+fN7B0zW2hmF1SxzXAzW2Nm86LbpKr2JSIijad1GtuUAb9y97lm1hGYY2b/cvd3Km33orufkPkSRUQkHbW20N19hbvPje6vA94Fujd2YSIiUjd16kM3szygAJhdxcMHm9lbZvaUmfWr5vnjzazYzIpXrlxZ52JFRKR6aQe6mXUAHgIudPe1lR6eC/Ry9wHAH4FHqtqHu09390J3L8zNza1vzSIiUoW0At3McghhXuTuD1d+3N3Xuvv66P6TQI6ZdctopSIiUqN0RrkYcDvwrrv/oZptdo+2w8yGRPstzWShIiJSs3RGuQwDzgDeNrN50brLgZ4A7n4LcCowwczKgI3AaHf3RqhXRESqUWugu/tLgNWyzZ+AP2WqKBERqTudKSoikhAKdBGRhFCgi4gkhAJdRCQhFOgiIgmhQBcRSQgFuohIQijQRUQSQoEuIpIQCnQRkYRQoIuIJIQCXUQkIRToIiIJoUAXEUkIBbqISEIo0EVEEkKBLiKSEAp0EZGEUKCLiCSEAl1EJCFqDXQz28vMnjezd8xsoZldUMU2ZmY3mtliM5tvZgMbp1wREalO6zS2KQN+5e5zzawjMMfM/uXu76RscyywT3QbCtwc/RQRkSZSawvd3Ve4+9zo/jrgXaB7pc1GAfd48BrQ2cz2yHi1IiJSrTr1oZtZHlAAzK70UHfgk5TlEr4d+pjZeDMrNrPilStX1q1SERGpUdqBbmYdgIeAC919bX1ezN2nu3uhuxfm5ubWZxciIlKNtALdzHIIYV7k7g9XscmnwF4pyz2idSIi0kTSGeViwO3Au+7+h2o2exQ4MxrtchCwxt1XZLBOERGpRTqjXIYBZwBvm9m8aN3lQE8Ad78FeBI4DlgMbAB+nPlSRUSkJrUGuru/BFgt2zjwi0wVJSIidaczRUVEEkKBLiKSEM0u0D/+GEaPhlWr4q5ERCS7NLtAnzcP/t//g4MPhg8/jLsaEZHs0ewCfeRIeOYZ+PJLGDoUXn457opERLJDswt0gMMOg9degy5d4Igj4L774q5IRCR+zTLQAfbZB159FQ46CE4/Ha65BtzjrkpEJD7NNtABunaFf/4TfvQjmDQJxo2DzZvjrkpEJB7pnCma1dq0gXvuCS32yZNh6dJw0LRLl7grExFpWs26hV7OLLTQi4pC3/pBB8HixXFXJSLStBIR6OVOPx2efTaMUR86FF58Me6KRESaTqICHeDQQ0MrvVs3OOoo+Otf465IRKRpJC7QAb7znTAC5pBD4IwzYMoUjYARkeRLZKBDOCj69NNw1llw1VVw5pkaASMiydbsR7nUZMcd4c47wwiY3/4Wli0LI2C6do27MhGRzEtsC72cGVxxRTib9PXXwwiY99+PuyoRkcxLfKCXGz0annsOVq8OF/aaNSvuikREMqvFBDqEg6SvvQa5uWEEzL33xl2RiEjmtKhAB/iP/wgjYA49NBwonTxZI2BEJBlaXKAD7LIL/OMf8OMfw9VXw9ixsGlT3FWJiDRMrYFuZneY2RdmtqCax4eb2RozmxfdJmW+zMzbcUe4/Xa47rpwwPSoo2DlyrirEhGpv3Ra6HcBx9SyzYvunh/drm54WU3DDC67DO6/H4qLwwiY996LuyoRkfqpNdDdfRaQ6Bk8f/ADmDkT1q0LI2Bmzoy7IhGRustUH/rBZvaWmT1lZv2q28jMxptZsZkVr8yy/o2DDoLZs2H33eH734e77467IhGRuslEoM8Fern7AOCPwCPVbeju09290N0Lc3NzM/DSmdW7N7zyChx+eJgs47e/hW++ibsqEZH0NDjQ3X2tu6+P7j8J5JhZtwZXFpPOneGpp+AnP4GpU8MleTUCRkSagwYHupntbmYW3R8S7bO0ofuNU04O3HorXH99OGB6xBEaASMi2a/Wi3OZ2X3AcKCbmZUAk4EcAHe/BTgVmGBmZcBGYLR78z9Vxwx+85twItIZZ4Q+9ieegL59465MRKRqFlf2FhYWenFxcSyvXVezZ8PIkbBlCzz0UGixi4jEwczmuHthVY+1yDNF62ro0BDqe+4JRx8Nd9wRd0UiIt+mQE9TXh68/DKMGBEOmF5+uUbAiEh2UaDXQefOoR99/Hj4r/+C44+He+4JE2eIiMQt0TMWNYacHLjlFujTB669NlzkC6BXL/jud7ff9t47HFgVEWkqOijaAN98AwsWwAsvbL99+WV4rHt3GD58e8Dvs48CXkQarqaDogr0DHKHd96pGPCffx4e2333ii34/fZTwItI3SnQY+Ie5i9NDfhPPw2P7bpruMRAecD36wc76IiGiNRCgZ4l3GHJknA1x/KA//jj8FjXrnDYYdsDvn9/aNUq1nJFJAsp0LPY0qUVW/BLloT1nTtXDPj8fGitQ9giLV5Nga6IiFleXriddVZY/uSTigH/2GNhfceOYR7U8oAfNCiMuBERKacWepZbvhxmzdoe8O++G9bvtBMMGxbC/cQTYf/9461TRJqGulwS5PPPKwb8ggWhr/2SS2DSJGjXLu4KRaQx6VouCbLbbnDaafCnP8Hbb8Nnn4XumuuvDwdSNX2eSMulQG/mdtsNbr8dnnkmnOg0YgSccw6sXh13ZSLS1BToCXHkkaHFfskl4WqQ++0HDz8cd1Ui0pQU6AnSvj387nfwxhvhzNRTTgm35cvjrkxEmoICPYEGDoTXXw/96k8+GUbA3HprOLFJRJJLgZ5QOTlhCr3586GgIFzy94gj4IMP4q5MRBqLTixKuH32geeeCwdOf/3rMBJmyhS4+GKdmJR0778fvqF17Ahdumy/de0afrZtG3eFkmkah96CLF8O550XDpbm58Ntt4UzTiVZli+Hq64KH+Jff139du3afTvkqwr+yut0rkO8GnTqv5ndAZwAfOHuB1TxuAH/CxwHbADGufvchpUsjWHPPcMk1w8/DL/8JQwZElrqV10VDqhK87Z6dTgofsMNUFYGEyaEb2VmsGpVuJWWbr9fed17721f3rKl+tdp2za94E9dzs3VN4KmUGsL3cwOB9YD91QT6McB5xECfSjwv+4+tLYXVgs9XqtXw6WXhoOle+8N06eHoY/S/GzaFE40u+46+OorOP10uOaa8HetD3fYsKH64K9ufWkpbN5c/X67dw819e4dfqbedt9d8wOkq8Gn/ptZHvB4NYH+F2Cmu98XLb8HDHf3FTXtszkHelERXHFFuPRtz54wdSqMHRt3VfXz/PPhgOnixXD22TBtGuyyS9xVSTrKysKctpMnQ0kJHHNMmOs2Pz++mjZurDr8ly+Hjz4KVxNdsiTMC5AaPe3ahaCvKux79w7XLpKgsa+22B34JGW5JFr3rUA3s/HAeICePXtm4KWbXlFRCMANG8LysmVhGZpnqI8YEUbCXH01/P73YRLsP/4RTj1VLaZs5Q5//ztcfnm4WNuQIXDvvWHKw7i1axda4t2717zd5s3h/055wKfeZs2Cdesqbr/rrt8O+vKw795dcweUy0QL/XHgend/KVp+FviNu9fY/G6uLfS8vPAPsbJevcK1zZuzefPgJz+BuXNh1Cj4859r/48pTWvWLJg4EV59NUxUft11cNJJyfrwdQ+t+qrC/qOPwjfj1IO9OTnh/2XloC+/36lTbL9Ko2jsFvqnwF4pyz2idYlUPsNQuuubk/x8mD07HFSbNCmckPS734Vrw2h6vHjNnw+XXRaGIe65Zzjm8eMfJ3PSE7NwULVrVxg8+NuPb90a5g2oHPRLloSzpFetqrh9ly7bw71v33Di3cCB0KNHsj4IITOB/ijwSzObQTgouqa2/vPmrGfPqlvozbQH6Vtatw4jI046KXQlnXtu6Ga69dbQIpSm9dFH4cO1qCi0NK+/Pgw9bcmjknJytgd0VVav3h7wqf32c+fCgw+Gi9gBdOu2PdzLb3vv3bxDPp1RLvcBw4FuwOfAZCAHwN1viYYt/gk4hjBs8ce1dbdA8+1yqdyHDuE/1/TpzbMPvSbucNddYWjjxo1w5ZVhZIxOSGp8K1fCtdfCzTeH/uHzzw9dLTpg3TAbNoRvO3Pnbr8tWBBa/RA+NAsKKob8vvtmVx+9JrjIsCSNcknHZ5+FQPm//4MDDwwnrFT1VVgabt06+MMfwmijDRvCyKPJk0P3gDSOzZtDqKeG/FtvbR+C2b596I5MDfn994+vYaNAl4z4+9/h5z8PAX/hhWFkjIaTZcaWLfCXv4Tx4ytXwsknh4ZC375xV9Yybd0KixZVDPk334R//zs83qZNaNyUB/ygQXDAAU1z8pQCXTJmzZrw1f+WW8LIgr/8Bb7//birar6++QZmzAjdWUuWhKGH118PQ2s9NU+a2jffhIvbpYb83LnbJ5Np3Rr69dse8gUFMGAAdOiQ2ToU6JJxs2aF0S/vvx+mwPuf/wmjEiQ97vCPf4SRK2+9Ff7jX389HH108z4o19K4h+HKqQE/Z074lgXhb5k6smbgwNB907lz/V9TgS6NYtOmcODuv/87HKwbM+bb1/DYZZft9zt3zq6DS3GZPTtc2viFF8J46WuvhdGjNTQ0KdzDmbGVW/IlJdu3ueyycA5BfSjQpVG99VY4aDpvHqxdW/O2nTtXDPnqwr/yuiRc2GnRonAw/eGHw5mPV14ZRkztuGPclUlT+OKL0A8/d83MJp4AAAhwSURBVC4UFsL3vle//SjQpcmUlYU+xaou4vTVVzWvT/dSr7V9IHTqBDvvvP1nu3bxdmN8+mm4Bv0dd4QRE5dcAhddFK5TLlJXjX2mqMg2rVuHEza6davb89zDkL10w//DD7efFbhxY+017bxzxVt52NdluW3bun0wfPVV6Be/8cbwYXXeeaGFnptbt/dGJF0KdMkKZtvDMy+vbs/dtGl70JeWhm6f8tuaNVUvf/ZZOKBbvrxpU+2vk/rBUNsHwKpV4RIKa9bAj34UhnjW9fcSqSsFujR7bdvCHnuEW31t2RK+IVT3AVDd8ooVYWKI8uXUD4bjjw8Hvvr3b/jvKJIOBboI4cBk+QWhGmLLlhDsZWVh0gaRpqRAF8mgHXes+/EDkUzRyFcRkYRQoIuIJIQCXUQkIRToIiIJoUAXEUkIBbqISEIo0EVEEkKBLiKSEGkFupkdY2bvmdliM5tYxePjzGylmc2Lbj/NfKkiIlKTWgPdzFoBfwaOBfYHxpjZ/lVser+750e32zJcp1ShqChc8GmHHcLPoqK4KxKROKVz6v8QYLG7LwEwsxnAKOCdxixMalZUFCZH2LAhLC9bFpYBxo6Nry4RiU86XS7dgU9SlkuidZWdYmbzzexBM9srI9VJta64YnuYl9uwIawXkZYpUwdFHwPy3L0/8C/g7qo2MrPxZlZsZsUry2dRlXr5+OO6rReR5Esn0D8FUlvcPaJ127h7qbtvjhZvAwZVtSN3n+7uhe5emKtpWxqkZ8+6rReR5Esn0N8A9jGz3ma2IzAaeDR1AzNLnVpgJPBu5kqUqkydGuanTNW+fVgvIi1TrYHu7mXAL4GnCUH9gLsvNLOrzWxktNn5ZrbQzN4CzgfGNVbBEowdC9OnQ69eYfq2Xr3Csg6IirRc5u6xvHBhYaEXFxfH8toiIs2Vmc1x98KqHtOZoiIiCaFAFxFJCAW6iEhCKNBFRBJCgS4ikhAKdBGRhFCgi4gkhAJdRCQhFOgiIgmhQJcG00QbItkhnQkuRKqliTZEsoda6NIgmmhDJHso0KVBNNGGSPZQoEuDZNNEG+rLl5ZOgS4Nki0TbZT35S9bBu7b+/IV6tKSKNClQbJloo1s6svXNwWJiya4kETYYYfQMq/MDL75punqqDzqB8I3Fs0mJZmiCS4k8bKlLz+bvilIy6NAl0TIlr78bBn1o26flkmBLomQLX352fBNIZsOEGfLB0u21NHo3L3WG3AM8B6wGJhYxeNtgPujx2cDebXtc9CgQS6SNH/9q3v79u4hSsOtffuwvqn06lXx9ctvvXo1XQ3u2fFeZFMd5bX06uVuFn7Wpwag2KvL6uoe2LYBtAI+BPYGdgTeAvavtM3PgVui+6OB+2vbrwJdkioT/2kbwqzqQDdr2jqy5YMlW+rI1AdLTYFe6ygXMzsYmOLuR0fLl0Ut+/9K2ebpaJtXzaw18BmQ6zXsXKNcRBpHXl7oZqmsVy9YurTp6siWkUfZUkem/i4NHeXSHfgkZbkkWlflNu5eBqwBulZRyHgzKzaz4pUrV6ZTu4jUUbYcIM6G4wnZVEdTHDBv0oOi7j7d3QvdvTA3N7cpX1qkxciWA8TZ8sGSLXU0xQdLOoH+KbBXynKPaF2V20RdLp2A0kwUKCJ1N3Zs+Br/zTfhZxwnNWXLB0u21NEUHyzp9KG3Bt4HjiQE9xvA6e6+MGWbXwAHuvu5ZjYaONndf1DTftWHLiItTVFROMns449Dy3zq1Lp/sNTUh17rBBfuXmZmvwSeJox4ucPdF5rZ1YSjrY8CtwP3mtliYBVhpIuIiKQYO7ZxvxmkNWORuz8JPFlp3aSU+5uA0zJbmoiI1IXOFBURSQgFuohIQijQRUQSQoEuIpIQsU1wYWYrgSpOhG1WugFfxl1EFtH7UZHej+30XlTUkPejl7tXeWZmbIGeBGZWXN140JZI70dFej+203tRUWO9H+pyERFJCAW6iEhCKNAbZnrcBWQZvR8V6f3YTu9FRY3yfqgPXUQkIdRCFxFJCAW6iEhCKNDrwcz2MrPnzewdM1toZhfEXVPczKyVmb1pZo/HXUvczKyzmT1oZovM7N1oGscWy8wuiv6fLDCz+8ysbdw1NSUzu8PMvjCzBSnrupjZv8zsg+jnLpl4LQV6/ZQBv3L3/YGDgF+Y2f4x1xS3C4B34y4iS/wv8A937wsMoAW/L2bWHTgfKHT3AwiX4G5pl9e+Czim0rqJwLPuvg/wbLTcYAr0enD3Fe4+N7q/jvAftvI8qy2GmfUAjgdui7uWuJlZJ+BwwhwBuPsWd18db1Wxaw20iybLaQ8sj7meJuXuswjzRKQaBdwd3b8bODETr6VAbyAzywMKgNnxVhKrG4BLgSacQz1r9QZWAndGXVC3mdlOcRcVF3f/FJgGfAysANa4+z/jrSor7ObuK6L7nwG7ZWKnCvQGMLMOwEPAhe6+Nu564mBmJwBfuPucuGvJEq2BgcDN7l4A/JsMfZ1ujqK+4VGED7o9gZ3M7EfxVpVdPIwdz8j4cQV6PZlZDiHMi9z94bjridEwYKSZLQVmAEeY2V/jLSlWJUCJu5d/Y3uQEPAt1VHAR+6+0t23Ag8Dh8RcUzb43Mz2AIh+fpGJnSrQ68HMjNBH+q67/yHueuLk7pe5ew93zyMc7HrO3VtsC8zdPwM+MbM+0aojgXdiLCluHwMHmVn76P/NkbTgg8QpHgXOiu6fBfw9EztVoNfPMOAMQmt0XnQ7Lu6iJGucBxSZ2XwgH7gu5npiE31TeRCYC7xNyJwWdRkAM7sPeBXoY2YlZvYT4Hrge2b2AeFbzPUZeS2d+i8ikgxqoYuIJIQCXUQkIRToIiIJoUAXEUkIBbqISEIo0EVEEkKBLiKSEP8fdx/dqwMAfkkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_AplDeH5hwn"
      },
      "source": [
        "test_dir = os.path.join(imdb_dir, 'test')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(test_dir, label_type)\n",
        "    for fname in sorted(os.listdir(dir_name)):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            texts.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
        "y_test = np.asarray(labels)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3N4wDoNXEs6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e0878021-033b-4848-8d0d-143e8dd68031"
      },
      "source": [
        "model.load_weights('pre_trained_glove_model.h5')\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 0.8328 - acc: 0.5549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8327580690383911, 0.5549200177192688]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hihzk8s8oV8U"
      },
      "source": [
        "## Hypertuning Embedding Layer 1 - 1000 Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "JZ07XouboV8l",
        "outputId": "ecfa8215-09ab-44a4-e8c4-b2c2af29248a"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqmfbPJuoV8o"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "# The Embedding layer takes at least two arguments:\n",
        "# the number of possible tokens, here 1000 (1 + maximum word index),\n",
        "# and the dimensionality of the embeddings, here 64.\n",
        "embedding_layer = Embedding(1000, 64)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ujaLuqsEoV8q",
        "outputId": "7662e2b9-e742-4417-8b70-5ff70579287c"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "\n",
        "# Number of words to consider as features\n",
        "max_features = 10000\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "maxlen = 150\n",
        "\n",
        "# Load the data as lists of integers.\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "x_train = x_train[:1000]\n",
        "y_train = y_train[:1000]\n",
        "\n",
        "# This turns our lists of integers\n",
        "# into a 2D integer tensor of shape `(samples, maxlen)`\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R8Tx5SMNoV8s",
        "outputId": "2ebef1c2-58c5-4f60-f450-75305ef2ad66"
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1syYsqaloV8u",
        "outputId": "a78ca6c5-9c8f-4658-fc42-38d20d8313b9"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "# We specify the maximum input length to our Embedding layer\n",
        "# so we can later flatten the embedded inputs\n",
        "model.add(Embedding(10000, 8, input_length=maxlen))\n",
        "# After the Embedding layer, \n",
        "# our activations have shape `(samples, maxlen, 8)`.\n",
        "\n",
        "# We flatten the 3D tensor of embeddings \n",
        "# into a 2D tensor of shape `(samples, maxlen * 8)`\n",
        "model.add(Flatten())\n",
        "\n",
        "# We add the classifier on top\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 150, 8)            80000     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1201      \n",
            "=================================================================\n",
            "Total params: 81,201\n",
            "Trainable params: 81,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 1s 11ms/step - loss: 0.6931 - acc: 0.4843 - val_loss: 0.6926 - val_acc: 0.5300\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6721 - acc: 0.8472 - val_loss: 0.6912 - val_acc: 0.5350\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6522 - acc: 0.9056 - val_loss: 0.6892 - val_acc: 0.5800\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6268 - acc: 0.9477 - val_loss: 0.6865 - val_acc: 0.5950\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5953 - acc: 0.9562 - val_loss: 0.6834 - val_acc: 0.6050\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5577 - acc: 0.9761 - val_loss: 0.6797 - val_acc: 0.6200\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5147 - acc: 0.9792 - val_loss: 0.6748 - val_acc: 0.6350\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4679 - acc: 0.9797 - val_loss: 0.6697 - val_acc: 0.6600\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4185 - acc: 0.9840 - val_loss: 0.6643 - val_acc: 0.6650\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3711 - acc: 0.9903 - val_loss: 0.6587 - val_acc: 0.6550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0FmN99luh9_"
      },
      "source": [
        "## Hypertuning Embedding Layer 2 - 850 Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "umZ5O8c_uh-B",
        "outputId": "29201eb9-a501-42fb-b455-86c391ab0bce"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGk7sR3Yuh-D"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "# The Embedding layer takes at least two arguments:\n",
        "# the number of possible tokens, here 1000 (1 + maximum word index),\n",
        "# and the dimensionality of the embeddings, here 64.\n",
        "embedding_layer = Embedding(1000, 64)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1HR4S93Auh-E",
        "outputId": "deb50f83-39f5-453a-e7ad-53344e42e9fd"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "\n",
        "# Number of words to consider as features\n",
        "max_features = 10000\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "maxlen = 150\n",
        "\n",
        "# Load the data as lists of integers.\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "x_train = x_train[:850]\n",
        "y_train = y_train[:850]\n",
        "\n",
        "# This turns our lists of integers\n",
        "# into a 2D integer tensor of shape `(samples, maxlen)`\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gSANb97iuh-G",
        "outputId": "fb1e9199-4edb-4ae0-da2d-0e150438caeb"
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DdwdSJECuh-I",
        "outputId": "ebfda21c-de9d-4081-edd4-81c45199d71c"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "# We specify the maximum input length to our Embedding layer\n",
        "# so we can later flatten the embedded inputs\n",
        "model.add(Embedding(10000, 8, input_length=maxlen))\n",
        "# After the Embedding layer, \n",
        "# our activations have shape `(samples, maxlen, 8)`.\n",
        "\n",
        "# We flatten the 3D tensor of embeddings \n",
        "# into a 2D tensor of shape `(samples, maxlen * 8)`\n",
        "model.add(Flatten())\n",
        "\n",
        "# We add the classifier on top\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 150, 8)            80000     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 1201      \n",
            "=================================================================\n",
            "Total params: 81,201\n",
            "Trainable params: 81,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 1s 11ms/step - loss: 0.6923 - acc: 0.5447 - val_loss: 0.6940 - val_acc: 0.4882\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6696 - acc: 0.7993 - val_loss: 0.6941 - val_acc: 0.4941\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6500 - acc: 0.9138 - val_loss: 0.6942 - val_acc: 0.5059\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6301 - acc: 0.9438 - val_loss: 0.6950 - val_acc: 0.4882\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6010 - acc: 0.9460 - val_loss: 0.6960 - val_acc: 0.4765\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5670 - acc: 0.9516 - val_loss: 0.6963 - val_acc: 0.4765\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5332 - acc: 0.9584 - val_loss: 0.6971 - val_acc: 0.4647\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4872 - acc: 0.9794 - val_loss: 0.6976 - val_acc: 0.4765\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4432 - acc: 0.9855 - val_loss: 0.6999 - val_acc: 0.4824\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4004 - acc: 0.9867 - val_loss: 0.7018 - val_acc: 0.4824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4uBm8weujon"
      },
      "source": [
        "## Hypertuning Embedding Layer 3 - 750 Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-EXd-MmWujoo",
        "outputId": "c1ef5e62-8e0f-49de-8478-e2f528165f03"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL0fY45fujoq"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "# The Embedding layer takes at least two arguments:\n",
        "# the number of possible tokens, here 1000 (1 + maximum word index),\n",
        "# and the dimensionality of the embeddings, here 64.\n",
        "embedding_layer = Embedding(1000, 64)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BtQeDK50ujow",
        "outputId": "34ae8ad6-cf4e-4b50-ca1c-6f6fc968ed9b"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "\n",
        "# Number of words to consider as features\n",
        "max_features = 10000\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "maxlen = 150\n",
        "\n",
        "# Load the data as lists of integers.\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "x_train = x_train[:750]\n",
        "y_train = y_train[:750]\n",
        "\n",
        "# This turns our lists of integers\n",
        "# into a 2D integer tensor of shape `(samples, maxlen)`\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "h-LFt1m_ujox",
        "outputId": "90c0356c-0f42-41dc-d5bb-8b54c4e192bc"
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a6u24WIgujoy",
        "outputId": "13951114-40c4-4af5-b66f-cb230d17e62d"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "# We specify the maximum input length to our Embedding layer\n",
        "# so we can later flatten the embedded inputs\n",
        "model.add(Embedding(10000, 8, input_length=maxlen))\n",
        "# After the Embedding layer, \n",
        "# our activations have shape `(samples, maxlen, 8)`.\n",
        "\n",
        "# We flatten the 3D tensor of embeddings \n",
        "# into a 2D tensor of shape `(samples, maxlen * 8)`\n",
        "model.add(Flatten())\n",
        "\n",
        "# We add the classifier on top\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 150, 8)            80000     \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 1201      \n",
            "=================================================================\n",
            "Total params: 81,201\n",
            "Trainable params: 81,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 1s 11ms/step - loss: 0.6919 - acc: 0.5258 - val_loss: 0.6952 - val_acc: 0.4533\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6710 - acc: 0.7942 - val_loss: 0.6960 - val_acc: 0.4600\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6523 - acc: 0.8755 - val_loss: 0.6969 - val_acc: 0.4733\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6250 - acc: 0.9316 - val_loss: 0.6974 - val_acc: 0.4733\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5980 - acc: 0.9518 - val_loss: 0.6981 - val_acc: 0.4733\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5673 - acc: 0.9539 - val_loss: 0.6988 - val_acc: 0.4733\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5310 - acc: 0.9697 - val_loss: 0.6998 - val_acc: 0.4600\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4921 - acc: 0.9677 - val_loss: 0.7005 - val_acc: 0.4467\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4517 - acc: 0.9696 - val_loss: 0.7014 - val_acc: 0.4667\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4029 - acc: 0.9647 - val_loss: 0.7020 - val_acc: 0.4733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4dHPYJ-ul9p"
      },
      "source": [
        "## Hypertuning Embedding Layer 4 - 900 Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "gi8IOPV3ul9q",
        "outputId": "9919bf74-0da7-48c6-ee46-ff902a6f22c7"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SHa8CzTul9s"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "# The Embedding layer takes at least two arguments:\n",
        "# the number of possible tokens, here 1000 (1 + maximum word index),\n",
        "# and the dimensionality of the embeddings, here 64.\n",
        "embedding_layer = Embedding(1000, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RSdzP7Lqul9t",
        "outputId": "8744c7a1-2fda-475b-a8b7-22b98835a1c5"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "\n",
        "# Number of words to consider as features\n",
        "max_features = 10000\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "maxlen = 150\n",
        "\n",
        "# Load the data as lists of integers.\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "x_train = x_train[:900]\n",
        "y_train = y_train[:900]\n",
        "\n",
        "# This turns our lists of integers\n",
        "# into a 2D integer tensor of shape `(samples, maxlen)`\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "A0DH5mxRul9u",
        "outputId": "a21c25fa-aef7-4fac-9bd2-4c466a80f2b1"
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Md_Eqdj-ul9w",
        "outputId": "d00f4e10-ba81-4fd9-d30b-4c3231f6859b"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "# We specify the maximum input length to our Embedding layer\n",
        "# so we can later flatten the embedded inputs\n",
        "model.add(Embedding(10000, 8, input_length=maxlen))\n",
        "# After the Embedding layer, \n",
        "# our activations have shape `(samples, maxlen, 8)`.\n",
        "\n",
        "# We flatten the 3D tensor of embeddings \n",
        "# into a 2D tensor of shape `(samples, maxlen * 8)`\n",
        "model.add(Flatten())\n",
        "\n",
        "# We add the classifier on top\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 150, 8)            80000     \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 1201      \n",
            "=================================================================\n",
            "Total params: 81,201\n",
            "Trainable params: 81,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "23/23 [==============================] - 1s 10ms/step - loss: 0.6918 - acc: 0.5087 - val_loss: 0.6922 - val_acc: 0.5167\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.6706 - acc: 0.8263 - val_loss: 0.6913 - val_acc: 0.5556\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.6495 - acc: 0.9258 - val_loss: 0.6903 - val_acc: 0.5389\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6231 - acc: 0.9547 - val_loss: 0.6895 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5934 - acc: 0.9712 - val_loss: 0.6884 - val_acc: 0.5444\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5602 - acc: 0.9673 - val_loss: 0.6867 - val_acc: 0.5444\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5213 - acc: 0.9777 - val_loss: 0.6852 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4748 - acc: 0.9718 - val_loss: 0.6839 - val_acc: 0.5611\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4254 - acc: 0.9823 - val_loss: 0.6830 - val_acc: 0.5722\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3768 - acc: 0.9888 - val_loss: 0.6818 - val_acc: 0.6056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0zqPCWDuor9"
      },
      "source": [
        "## Hypertuning Embedding Layer 5 - 875 Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8trdx_uIuor-",
        "outputId": "9919bf74-0da7-48c6-ee46-ff902a6f22c7"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWZoT4Tzuor_"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "# The Embedding layer takes at least two arguments:\n",
        "# the number of possible tokens, here 1000 (1 + maximum word index),\n",
        "# and the dimensionality of the embeddings, here 64.\n",
        "embedding_layer = Embedding(1000, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "H7XyeJbjuosA",
        "outputId": "55827546-9a1a-4ed3-f3d3-6cb7808cd434"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "\n",
        "# Number of words to consider as features\n",
        "max_features = 10000\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "maxlen = 150\n",
        "\n",
        "# Load the data as lists of integers.\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "x_train = x_train[:875]\n",
        "y_train = y_train[:875]\n",
        "\n",
        "# This turns our lists of integers\n",
        "# into a 2D integer tensor of shape `(samples, maxlen)`\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3NvWjXi0uosC",
        "outputId": "6e559e96-8928-475c-e67f-280ca5d01416"
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cfd9hsBOuosD",
        "outputId": "3f4d2017-2a36-4a9e-f8f4-6fa8bb92a0ce"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "# We specify the maximum input length to our Embedding layer\n",
        "# so we can later flatten the embedded inputs\n",
        "model.add(Embedding(10000, 8, input_length=maxlen))\n",
        "# After the Embedding layer, \n",
        "# our activations have shape `(samples, maxlen, 8)`.\n",
        "\n",
        "# We flatten the 3D tensor of embeddings \n",
        "# into a 2D tensor of shape `(samples, maxlen * 8)`\n",
        "model.add(Flatten())\n",
        "\n",
        "# We add the classifier on top\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 150, 8)            80000     \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 1201      \n",
            "=================================================================\n",
            "Total params: 81,201\n",
            "Trainable params: 81,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 1s 11ms/step - loss: 0.6931 - acc: 0.4920 - val_loss: 0.6941 - val_acc: 0.4857\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6726 - acc: 0.7996 - val_loss: 0.6937 - val_acc: 0.4971\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6530 - acc: 0.9294 - val_loss: 0.6933 - val_acc: 0.4857\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6285 - acc: 0.9506 - val_loss: 0.6927 - val_acc: 0.4857\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6031 - acc: 0.9466 - val_loss: 0.6919 - val_acc: 0.4971\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5682 - acc: 0.9560 - val_loss: 0.6911 - val_acc: 0.4971\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5313 - acc: 0.9629 - val_loss: 0.6902 - val_acc: 0.5143\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4848 - acc: 0.9716 - val_loss: 0.6889 - val_acc: 0.5257\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4432 - acc: 0.9643 - val_loss: 0.6877 - val_acc: 0.5429\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3988 - acc: 0.9789 - val_loss: 0.6862 - val_acc: 0.5543\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}